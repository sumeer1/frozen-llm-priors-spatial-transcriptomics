{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad6eb8ee",
   "metadata": {},
   "source": [
    "# Welch t-test evaluation (frozen priors)\n",
    "\n",
    "This notebook reproduces the **main results** using **frozen priors** saved by Notebook 01.\n",
    "\n",
    "- No LLM calls\n",
    "- Deterministic given the same seed and frozen JSON files\n",
    "\n",
    "\n",
    "**Prerequisite:** We need an `AnnData` object named `adata` in memory (same preprocessing / `var_names` as used to build the frozen priors). Either we can run Notebook 01 first in the same runtime, or load the same `.h5ad` here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bf71d5",
   "metadata": {},
   "source": [
    "## 0) Imports + load frozen priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import anndata as ad\n",
    "\n",
    "import re, math\n",
    "import numpy as np, pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Set this to the dataset path (e.g., a preprocessed MERFISH .h5ad).\n",
    "DATA_PATH = os.environ.get('MERFISH_H5AD', '')\n",
    "\n",
    "if 'adata' not in globals():\n",
    "    if not DATA_PATH:\n",
    "        raise ValueError(\"`adata` not found. Run Notebook 01 first or set MERFISH_H5AD / DATA_PATH to a .h5ad file.\")\n",
    "    adata = ad.read_h5ad(DATA_PATH)\n",
    "\n",
    "print('adata:', adata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a65570",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# housekeeping / panel filter (keep consistent with synthesis)\n",
    "HOUSEKEEPING_RE = r'^(Rpl|Rps|Mrpl|Mrps|mt\\-|Mt\\-)'\n",
    "panel = set(map(str, adata.var_names))\n",
    "MIN_GENES = 3\n",
    "\n",
    "def _hk_filter_to_panel(gs, panel=panel):\n",
    "    gs = [str(g) for g in gs if str(g) in panel]\n",
    "    gs = [g for g in gs if not re.match(HOUSEKEEPING_RE, g)]\n",
    "    out, seen = [], set()\n",
    "    for g in gs:\n",
    "        if g not in seen:\n",
    "            seen.add(g); out.append(g)\n",
    "    return out\n",
    "\n",
    "def _aggregate_scores(X_slice, gene_idx, weights=None, agg=\"weighted\", trim_pct=0.10):\n",
    "    \"\"\"\n",
    "    X_slice: (n_cells, n_genes_all) view for pos or neg\n",
    "    gene_idx: np.array of selected gene indices\n",
    "    weights: np.array of weights aligned to gene_idx (or None)\n",
    "    agg: \"weighted\" | \"trimmed_mean\" \n",
    "    \"\"\"\n",
    "    if len(gene_idx) == 0:\n",
    "        return None\n",
    "    sub = X_slice[:, gene_idx]  \n",
    "    if agg == \"weighted\":\n",
    "        if weights is None:\n",
    "            return sub.mean(axis=1)\n",
    "        w = np.asarray(weights, float)\n",
    "        w = np.clip(w, 1e-6, np.inf)\n",
    "        return (sub * w).sum(axis=1) / (w.sum())\n",
    "    elif agg == \"trimmed_mean\":\n",
    "        n = sub.shape[1]\n",
    "        k = int(n * trim_pct)\n",
    "        if k == 0:\n",
    "            return sub.mean(axis=1)\n",
    "        sub_sorted = np.sort(sub, axis=1)\n",
    "        core = sub_sorted[:, k: n-k] if (n - 2*k) > 0 else sub_sorted[:, :1]\n",
    "        return core.mean(axis=1)\n",
    "    else:\n",
    "        return sub.mean(axis=1)\n",
    "\n",
    "def _cohens_d_posneg(pos, neg):\n",
    "    pos = np.asarray(pos, float); neg = np.asarray(neg, float)\n",
    "    if len(pos) < 2 or len(neg) < 2:\n",
    "        return np.nan\n",
    "    mx, my = pos.mean(), neg.mean()\n",
    "    vx, vy = pos.var(ddof=1), neg.var(ddof=1)\n",
    "    denom = (len(pos) + len(neg) - 2)\n",
    "    if denom <= 0:\n",
    "        return np.nan\n",
    "    sp2 = ((len(pos)-1)*vx + (len(neg)-1)*vy) / denom\n",
    "    if not np.isfinite(sp2) or sp2 <= 0:\n",
    "        return np.nan\n",
    "    return (mx - my) / math.sqrt(sp2)\n",
    "\n",
    "def classify_by_ttest_custom(\n",
    "    adata, sets_dict, weights_dict=None, K=100, neg_per_pos=5,\n",
    "    agg=\"weighted\", trim_pct=0.10, seed=42, boot_idx=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Held-out Welch (pos>neg) classification using custom aggregation.\n",
    "\n",
    "    For each *true* class (row):\n",
    "      - sample K held-out positives (y==true) and neg_per_pos*K held-out negatives (y!=true)\n",
    "      - for each candidate class, aggregate expression over its gene set\n",
    "      - run one-sided Welch t-test: H1 mean(pos_scores) > mean(neg_scores)\n",
    "      - predict the candidate with the smallest p-value among those with positive mean difference\n",
    "\n",
    "    boot_idx is treated as an exclusion set (e.g., train_idx), preventing leakage.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    X = adata.X.toarray() if hasattr(adata.X, 'toarray') else np.asarray(adata.X)\n",
    "    y = adata.obs['Cell_class'].astype(str).values\n",
    "    g = np.array(adata.var_names, dtype=str)\n",
    "    g2i = {gg: i for i, gg in enumerate(g)}\n",
    "    classes = sorted([c for c in sets_dict.keys() if len(sets_dict[c]) >= MIN_GENES])\n",
    "\n",
    "    # exclude any provided bootstrap/train indices\n",
    "    idx_all = np.arange(adata.n_obs)\n",
    "    mask_notboot = np.ones(len(idx_all), dtype=bool)\n",
    "    if boot_idx is not None:\n",
    "        boot_idx = np.asarray(boot_idx, dtype=int)\n",
    "        if boot_idx.size > 0:\n",
    "            mask_notboot[boot_idx] = False\n",
    "\n",
    "    preds, rows = [], []\n",
    "    for true_c in classes:\n",
    "        pos_pool = np.where(mask_notboot & (y == true_c))[0]\n",
    "        neg_pool = np.where(mask_notboot & (y != true_c))[0]\n",
    "        n_pos = min(K, len(pos_pool))\n",
    "        n_neg = min(max(neg_per_pos * n_pos, n_pos), len(neg_pool)) if n_pos > 0 else 0\n",
    "\n",
    "        if n_pos < 2 or n_neg < 2:\n",
    "            preds.append((\"None\", true_c))\n",
    "            continue\n",
    "\n",
    "        pos_idx = rng.choice(pos_pool, size=n_pos, replace=False)\n",
    "        neg_idx = rng.choice(neg_pool, size=n_neg, replace=False)\n",
    "\n",
    "        best_p, best_c = 1.0, None\n",
    "        for cand in classes:\n",
    "            genes = [gg for gg in sets_dict[cand] if gg in g2i]\n",
    "            if len(genes) < MIN_GENES:\n",
    "                continue\n",
    "\n",
    "            gi = np.array([g2i[gg] for gg in genes], int)\n",
    "\n",
    "            w = None\n",
    "            if weights_dict is not None and cand in weights_dict:\n",
    "                w = np.array([weights_dict[cand].get(gg, 1.0) for gg in genes], float)\n",
    "\n",
    "            pos_scores = _aggregate_scores(X[pos_idx], gi, weights=w, agg=agg, trim_pct=trim_pct)\n",
    "            neg_scores = _aggregate_scores(X[neg_idx], gi, weights=w, agg=agg, trim_pct=trim_pct)\n",
    "            if pos_scores is None or neg_scores is None:\n",
    "                continue\n",
    "\n",
    "            diff = float(np.mean(pos_scores) - np.mean(neg_scores))\n",
    "            p = ttest_ind(pos_scores, neg_scores, equal_var=False, alternative='greater').pvalue\n",
    "\n",
    "            if (diff > 0) and (p < best_p):\n",
    "                best_p, best_c = p, cand\n",
    "\n",
    "            if cand == true_c:\n",
    "                d = _cohens_d_posneg(pos_scores, neg_scores)\n",
    "                rows.append({\"class\": true_c, \"diag_p\": float(p), \"diag_d\": float(d)})\n",
    "\n",
    "        preds.append((best_c if best_c is not None else classes[0], true_c))\n",
    "\n",
    "    df_pred = pd.DataFrame({\"class\": [t for (_, t) in preds], \"predicted\": [p for (p, _) in preds]})\n",
    "    df_pred[\"correct\"] = (df_pred[\"class\"] == df_pred[\"predicted\"])\n",
    "    acc = float(df_pred[\"correct\"].mean()) if len(df_pred) else np.nan\n",
    "    diag = pd.DataFrame(rows).groupby(\"class\", as_index=True).last()\n",
    "    return acc, df_pred, diag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67658370",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = \"./\"  \n",
    "\n",
    "with open(os.path.join(OUTDIR, \"ref_llm_top.json\")) as f:\n",
    "    ref_llm_top = {c: set(gs) for c, gs in json.load(f).items()}\n",
    "with open(os.path.join(OUTDIR, \"ref_llm_w.json\")) as f:\n",
    "    tmp = json.load(f)\n",
    "    ref_llm_w = {c: {g: float(w) for g, w in inner.items()} for c, inner in tmp.items()}\n",
    "\n",
    "with open(os.path.join(OUTDIR, \"marker_top.json\")) as f:\n",
    "    marker_top = {c: set(gs) for c, gs in json.load(f).items()}\n",
    "with open(os.path.join(OUTDIR, \"marker_w.json\")) as f:\n",
    "    tmp = json.load(f)\n",
    "    marker_w = {c: {g: float(w) for g, w in inner.items()} for c, inner in tmp.items()}\n",
    "\n",
    "with open(os.path.join(OUTDIR, \"split.json\")) as f:\n",
    "    split = json.load(f)\n",
    "    train_idx = np.array(split[\"train_idx\"], int)\n",
    "    test_idx  = np.array(split[\"test_idx\"],  int)\n",
    "\n",
    "print(\"Loaded classes:\", len(ref_llm_top), \"| Train:\", len(train_idx), \"| Test:\", len(test_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678c056b",
   "metadata": {},
   "source": [
    "## 1) Welch evaluation functions \n",
    "\n",
    "- sample K positives from class c (excluding `boot_idx`)\n",
    "- sample `neg_per_pos*K` negatives\n",
    "- compute aggregated score for each candidate gene set\n",
    "- pick candidate with smallest p-value (subject to positive mean difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa80567",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_GENES = 3\n",
    "\n",
    "def _aggregate_scores(X_slice, gene_idx, weights=None, agg=\"weighted\", trim_pct=0.10):\n",
    "    if len(gene_idx) == 0:\n",
    "        return None\n",
    "    sub = X_slice[:, gene_idx]\n",
    "    if agg == \"weighted\":\n",
    "        if weights is None:\n",
    "            return sub.mean(axis=1)\n",
    "        w = np.asarray(weights, float)\n",
    "        w = np.clip(w, 1e-6, np.inf)\n",
    "        return (sub * w).sum(axis=1) / w.sum()\n",
    "    elif agg == \"trimmed_mean\":\n",
    "        n = sub.shape[1]\n",
    "        k = int(n * trim_pct)\n",
    "        if k == 0:\n",
    "            return sub.mean(axis=1)\n",
    "        sub_sorted = np.sort(sub, axis=1)\n",
    "        core = sub_sorted[:, k:n-k] if (n - 2*k) > 0 else sub_sorted[:, :1]\n",
    "        return core.mean(axis=1)\n",
    "    else:\n",
    "        return sub.mean(axis=1)\n",
    "\n",
    "\n",
    "def _cohens_d(pos, neg):\n",
    "    pos = np.asarray(pos, float); neg = np.asarray(neg, float)\n",
    "    if len(pos) < 2 or len(neg) < 2:\n",
    "        return np.nan\n",
    "    vx, vy = pos.var(ddof=1), neg.var(ddof=1)\n",
    "    denom = (len(pos) + len(neg) - 2)\n",
    "    sp2 = ((len(pos)-1)*vx + (len(neg)-1)*vy) / denom if denom > 0 else np.nan\n",
    "    if not np.isfinite(sp2) or sp2 <= 0:\n",
    "        return np.nan\n",
    "    return (pos.mean() - neg.mean()) / math.sqrt(sp2)\n",
    "\n",
    "def classify_by_ttest_custom(\n",
    "    adata, sets_dict, weights_dict=None, K=100, neg_per_pos=5,\n",
    "    agg=\"weighted\", trim_pct=0.10, seed=42, boot_idx=None\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    X = adata.X.toarray() if hasattr(adata.X, \"toarray\") else np.asarray(adata.X)\n",
    "    y = adata.obs[\"Cell_class\"].astype(str).values\n",
    "    g = np.array(adata.var_names, dtype=str)\n",
    "    g2i = {gg: i for i, gg in enumerate(g)}\n",
    "    classes = sorted([c for c in sets_dict.keys() if len(sets_dict[c]) >= MIN_GENES])\n",
    "\n",
    "    idx_all = np.arange(adata.n_obs)\n",
    "    mask_notboot = np.ones(len(idx_all), dtype=bool)\n",
    "    if boot_idx is not None:\n",
    "        boot_idx = np.asarray(boot_idx, dtype=int)\n",
    "        if boot_idx.size > 0:\n",
    "            mask_notboot[boot_idx] = False\n",
    "\n",
    "    preds, diag_rows = [], []\n",
    "    for true_c in classes:\n",
    "        pos_pool = np.where(mask_notboot & (y == true_c))[0]\n",
    "        neg_pool = np.where(mask_notboot & (y != true_c))[0]\n",
    "        n_pos = min(K, len(pos_pool))\n",
    "        n_neg = min(max(neg_per_pos * n_pos, n_pos), len(neg_pool)) if n_pos > 0 else 0\n",
    "        if n_pos < 2 or n_neg < 2:\n",
    "            preds.append((\"None\", true_c))\n",
    "            continue\n",
    "\n",
    "        pos_idx = rng.choice(pos_pool, size=n_pos, replace=False)\n",
    "        neg_idx = rng.choice(neg_pool, size=n_neg, replace=False)\n",
    "\n",
    "        best_p, best_c = 1.0, None\n",
    "        for cand in classes:\n",
    "            genes = [gg for gg in sets_dict[cand] if gg in g2i]\n",
    "            if len(genes) < MIN_GENES:\n",
    "                continue\n",
    "            gi = np.array([g2i[gg] for gg in genes], int)\n",
    "\n",
    "            w = None\n",
    "            if weights_dict is not None and cand in weights_dict:\n",
    "                w = np.array([weights_dict[cand].get(gg, 1.0) for gg in genes], float)\n",
    "\n",
    "            pos_scores = _aggregate_scores(X[pos_idx], gi, weights=w, agg=agg, trim_pct=trim_pct)\n",
    "            neg_scores = _aggregate_scores(X[neg_idx], gi, weights=w, agg=agg, trim_pct=trim_pct)\n",
    "            if pos_scores is None or neg_scores is None:\n",
    "                continue\n",
    "\n",
    "            diff = float(pos_scores.mean() - neg_scores.mean())\n",
    "            p = ttest_ind(pos_scores, neg_scores, equal_var=False, alternative=\"greater\").pvalue\n",
    "\n",
    "            if (diff > 0) and (p < best_p):\n",
    "                best_p, best_c = p, cand\n",
    "\n",
    "            if cand == true_c:\n",
    "                diag_rows.append({\"class\": true_c, \"diag_p\": float(p), \"diag_d\": float(_cohens_d(pos_scores, neg_scores))})\n",
    "\n",
    "        preds.append((best_c if best_c is not None else classes[0], true_c))\n",
    "\n",
    "    df_pred = pd.DataFrame({\"class\": [t for (_, t) in preds],\n",
    "                            \"predicted\": [p for (p, _) in preds]})\n",
    "    df_pred[\"correct\"] = (df_pred[\"class\"] == df_pred[\"predicted\"])\n",
    "    acc = float(df_pred[\"correct\"].mean()) if len(df_pred) else np.nan\n",
    "    diag = pd.DataFrame(diag_rows).groupby(\"class\", as_index=True).last()\n",
    "    return acc, df_pred, diag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181f9d90",
   "metadata": {},
   "source": [
    "## 2) Sweep over seeds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210d5edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep(seeds=(1,2,3,4,5)):\n",
    "    llm, mrk = [], []\n",
    "    for s in seeds:\n",
    "        aL, _, _ = classify_by_ttest_custom(\n",
    "            adata, ref_llm_top, ref_llm_w,\n",
    "            K=100, neg_per_pos=5, agg=\"weighted\",\n",
    "            trim_pct=0.10, seed=s, boot_idx=train_idx\n",
    "        )\n",
    "        aM, _, _ = classify_by_ttest_custom(\n",
    "            adata, marker_top, marker_w,\n",
    "            K=100, neg_per_pos=5, agg=\"weighted\",\n",
    "            trim_pct=0.10, seed=s, boot_idx=train_idx\n",
    "        )\n",
    "        llm.append(aL); mrk.append(aM)\n",
    "    return (float(np.mean(llm)), float(np.std(llm))), (float(np.mean(mrk)), float(np.std(mrk)))\n",
    "\n",
    "print(\"LLM mean±sd, Markers mean±sd:\", sweep())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
