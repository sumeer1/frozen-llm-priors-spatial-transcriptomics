{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-platform transfer (MERFISH → Stereo-seq) using frozen priors\n",
    "\n",
    "This notebook evaluates **transfer** of **frozen LLM gene-set priors** (learned once on MERFISH) onto a **new spatial technology** dataset (e.g., Stereo-seq).\n",
    "\n",
    "**Workflow**\n",
    "- Load frozen priors from disk (`ref_llm_top.json`, `ref_llm_w.json`) and the matched marker baseline (`marker_top.json`, `marker_w.json`).\n",
    "- Map the new dataset’s raw labels into the same **macro classes** used for MERFISH.\n",
    "- Intersect priors/markers with the new dataset gene panel (and remove housekeeping genes).\n",
    "- Run the **Welch one-sided** classifier (`classify_by_ttest_custom`) used in the paper.\n",
    "- Seed sweep + paired stats plot.\n",
    "\n",
    "**Note:** This notebook does **not** run any LLM calls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import ttest_ind, ttest_rel, wilcoxon, t as student_t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Inputs\n",
    "Provide the new dataset AnnData as `adataX` (Stereo-seq) before running.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New technology dataset (e.g., Stereo-seq)\n",
    "adata_new = adataX.copy()  \n",
    "\n",
    "# Folder containing frozen priors \n",
    "OUTDIR = \"./\"       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Load frozen priors + marker baseline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(OUTDIR, \"ref_llm_top.json\")) as f:\n",
    "    ref_llm_top = {c: set(gs) for c, gs in json.load(f).items()}\n",
    "\n",
    "with open(os.path.join(OUTDIR, \"ref_llm_w.json\")) as f:\n",
    "    _w = json.load(f)\n",
    "    ref_llm_w = {c: {g: float(w) for g, w in gm.items()} for c, gm in _w.items()}\n",
    "\n",
    "with open(os.path.join(OUTDIR, \"marker_top.json\")) as f:\n",
    "    marker_top = {c: set(gs) for c, gs in json.load(f).items()}\n",
    "\n",
    "with open(os.path.join(OUTDIR, \"marker_w.json\")) as f:\n",
    "    _mw = json.load(f)\n",
    "    marker_w = {c: {g: float(w) for g, w in gm.items()} for c, gm in _mw.items()}\n",
    "\n",
    "print(\"Loaded classes (LLM):\", len(ref_llm_top))\n",
    "print(\"Loaded classes (MRK):\", len(marker_top))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Map new dataset labels → MERFISH macro classes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_CLASSES = ['Astrocyte','Endothelial','Ependymal','Excitatory','Inhibitory',\n",
    "               'Microglia','OD Immature','OD Mature','Pericytes']\n",
    "\n",
    "RAW_COL = \"annotation\"  \n",
    "\n",
    "mapper = {\n",
    "    r\"^Astro.*\":         \"Astrocyte\",\n",
    "    r\"^Endoth.*\":        \"Endothelial\",\n",
    "    r\"^Ependym.*\":       \"Ependymal\",\n",
    "    r\"^(Ex|Excit).*\":    \"Excitatory\",\n",
    "    r\"^(Inh|GABA).*\":    \"Inhibitory\",\n",
    "    r\"^Microglia.*\":     \"Microglia\",\n",
    "    r\"^(OPC|OD Imm).*\":  \"OD Immature\",\n",
    "    r\"^(Oligodendro).*\": \"OD Mature\",\n",
    "    r\"^(Pericyte|VSMC|VLMC).*\": \"Pericytes\",\n",
    "}\n",
    "\n",
    "def to_macro(label):\n",
    "    s = str(label)\n",
    "    for pat, target in mapper.items():\n",
    "        if re.search(pat, s, flags=re.I):\n",
    "            return target\n",
    "    return \"Unknown\"\n",
    "\n",
    "adata_new.obs[\"Cell_class\"] = adata_new.obs[RAW_COL].map(to_macro)\n",
    "print(\"Per-class counts in new dataset:\\n\", adata_new.obs[\"Cell_class\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Panel intersection + housekeeping filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOUSEKEEPING_RE = r'^(Rpl|Rps|Mrpl|Mrps|mt\\-|Mt\\-)'\n",
    "MIN_GENES = 3\n",
    "panel_new = set(map(str, adata_new.var_names))\n",
    "\n",
    "def hk_filter_to_panel(gs, panel):\n",
    "    out, seen = [], set()\n",
    "    for g in gs:\n",
    "        g = str(g)\n",
    "        if g in panel and not re.match(HOUSEKEEPING_RE, g) and g not in seen:\n",
    "            seen.add(g); out.append(g)\n",
    "    return out\n",
    "\n",
    "def renorm_weights_mean1(wdict):\n",
    "    vals = np.array(list(wdict.values()), float)\n",
    "    if vals.size == 0:\n",
    "        return wdict\n",
    "    s = float(np.nansum(vals))\n",
    "    if not np.isfinite(s) or s <= 0:\n",
    "        return {k: 1.0 for k in wdict}\n",
    "    scale = len(vals) / s\n",
    "    return {k: float(v) * scale for k, v in wdict.items()}\n",
    "\n",
    "# Filter priors + weights\n",
    "ref_llm_top_X, ref_llm_w_X = {}, {}\n",
    "for c, s in ref_llm_top.items():\n",
    "    keep = hk_filter_to_panel(s, panel_new)\n",
    "    if len(keep) >= MIN_GENES:\n",
    "        ref_llm_top_X[c] = set(keep)\n",
    "        w = {g: max(ref_llm_w.get(c, {}).get(g, 0.0), 0.0) for g in keep}\n",
    "        ref_llm_w_X[c] = renorm_weights_mean1(w)\n",
    "\n",
    "# Filter markers + weights\n",
    "marker_top_X, marker_w_X = {}, {}\n",
    "for c, s in marker_top.items():\n",
    "    keep = hk_filter_to_panel(s, panel_new)\n",
    "    if len(keep) >= MIN_GENES:\n",
    "        marker_top_X[c] = set(keep)\n",
    "        w = {g: float(marker_w.get(c, {}).get(g, 1.0)) for g in keep}\n",
    "        marker_w_X[c] = renorm_weights_mean1(w)\n",
    "\n",
    "# Keep only classes present in new dataset and macro list\n",
    "present = set(adata_new.obs[\"Cell_class\"].astype(str).unique()) & set(ALL_CLASSES)\n",
    "ref_llm_top_X = {c: s for c, s in ref_llm_top_X.items() if c in present}\n",
    "ref_llm_w_X   = {c: w for c, w in ref_llm_w_X.items()   if c in present}\n",
    "marker_top_X  = {c: s for c, s in marker_top_X.items()  if c in present}\n",
    "marker_w_X    = {c: w for c, w in marker_w_X.items()    if c in present}\n",
    "\n",
    "print(\"Classes evaluated:\", sorted(ref_llm_top_X.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Welch t-test classifier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _aggregate_scores(X_slice, gene_idx, weights=None, agg=\"weighted\", trim_pct=0.10):\n",
    "    if len(gene_idx) == 0:\n",
    "        return None\n",
    "    sub = X_slice[:, gene_idx]\n",
    "    if agg == \"weighted\":\n",
    "        if weights is None:\n",
    "            return sub.mean(axis=1)\n",
    "        w = np.asarray(weights, float)\n",
    "        w = np.clip(w, 1e-6, np.inf)\n",
    "        return (sub * w).sum(axis=1) / (w.sum())\n",
    "    elif agg == \"trimmed_mean\":\n",
    "        n = sub.shape[1]\n",
    "        k = int(n * trim_pct)\n",
    "        if k == 0:\n",
    "            return sub.mean(axis=1)\n",
    "        sub_sorted = np.sort(sub, axis=1)\n",
    "        core = sub_sorted[:, k: n-k] if (n - 2*k) > 0 else sub_sorted[:, :1]\n",
    "        return core.mean(axis=1)\n",
    "    else:\n",
    "        return sub.mean(axis=1)\n",
    "\n",
    "def _cohens_d_posneg(pos, neg):\n",
    "    pos = np.asarray(pos, float); neg = np.asarray(neg, float)\n",
    "    if len(pos) < 2 or len(neg) < 2:\n",
    "        return np.nan\n",
    "    mx, my = pos.mean(), neg.mean()\n",
    "    vx, vy = pos.var(ddof=1), neg.var(ddof=1)\n",
    "    sp2 = ((len(pos)-1)*vx + (len(neg)-1)*vy) / max(len(pos)+len(neg)-2, 1)\n",
    "    if not np.isfinite(sp2) or sp2 <= 0:\n",
    "        return np.nan\n",
    "    return (mx - my) / math.sqrt(sp2)\n",
    "\n",
    "def classify_by_ttest_custom(\n",
    "    adata, sets_dict, weights_dict=None, K=100, neg_per_pos=5,\n",
    "    agg=\"weighted\", trim_pct=0.10, seed=42, boot_idx=None\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    X = adata.X.toarray() if hasattr(adata.X, 'toarray') else np.asarray(adata.X)\n",
    "    y = adata.obs['Cell_class'].astype(str).values\n",
    "    g = np.array(adata.var_names, dtype=str)\n",
    "    g2i = {gg:i for i,gg in enumerate(g)}\n",
    "    classes = sorted([c for c in sets_dict.keys() if len(sets_dict[c]) >= MIN_GENES])\n",
    "\n",
    "    idx_all = np.arange(adata.n_obs)\n",
    "    mask_notboot = np.ones(len(idx_all), dtype=bool)\n",
    "    if boot_idx is not None:\n",
    "        boot_idx = np.asarray(boot_idx, dtype=int)\n",
    "        if boot_idx.size > 0:\n",
    "            mask_notboot[boot_idx] = False\n",
    "\n",
    "    preds, rows = [], []\n",
    "    for true_c in classes:\n",
    "        pos_pool = np.where(mask_notboot & (y == true_c))[0]\n",
    "        neg_pool = np.where(mask_notboot & (y != true_c))[0]\n",
    "        n_pos = min(K, len(pos_pool))\n",
    "        n_neg = min(max(neg_per_pos * n_pos, n_pos), len(neg_pool)) if n_pos > 0 else 0\n",
    "        if n_pos < 2 or n_neg < 2:\n",
    "            preds.append((\"None\", true_c))\n",
    "            continue\n",
    "\n",
    "        pos_idx = rng.choice(pos_pool, size=n_pos, replace=False)\n",
    "        neg_idx = rng.choice(neg_pool, size=n_neg, replace=False)\n",
    "\n",
    "        best_p, best_c = 1.0, None\n",
    "        for cand in classes:\n",
    "            genes = [gg for gg in sets_dict[cand] if gg in g2i]\n",
    "            if len(genes) < MIN_GENES:\n",
    "                continue\n",
    "            gi = np.array([g2i[gg] for gg in genes], int)\n",
    "\n",
    "            w = None\n",
    "            if weights_dict is not None and cand in weights_dict:\n",
    "                w = np.array([weights_dict[cand].get(gg, 1.0) for gg in genes], float)\n",
    "\n",
    "            pos_scores = _aggregate_scores(X[pos_idx], gi, weights=w, agg=agg, trim_pct=trim_pct)\n",
    "            neg_scores = _aggregate_scores(X[neg_idx], gi, weights=w, agg=agg, trim_pct=trim_pct)\n",
    "            if pos_scores is None or neg_scores is None:\n",
    "                continue\n",
    "\n",
    "            diff = float(pos_scores.mean() - neg_scores.mean())\n",
    "            p = ttest_ind(pos_scores, neg_scores, equal_var=False, alternative='greater').pvalue\n",
    "            if (diff > 0) and (p < best_p):\n",
    "                best_p, best_c = p, cand\n",
    "\n",
    "            if cand == true_c:\n",
    "                d = _cohens_d_posneg(pos_scores, neg_scores)\n",
    "                rows.append({\"class\": true_c, \"diag_p\": float(p), \"diag_d\": float(d)})\n",
    "\n",
    "        preds.append((best_c if best_c is not None else classes[0], true_c))\n",
    "\n",
    "    df_pred = pd.DataFrame({\"class\": [t for (_, t) in preds],\n",
    "                            \"predicted\": [p for (p, _) in preds]})\n",
    "    df_pred[\"correct\"] = (df_pred[\"class\"] == df_pred[\"predicted\"])\n",
    "    acc = float(df_pred[\"correct\"].mean()) if len(df_pred) else np.nan\n",
    "    diag = pd.DataFrame(rows).groupby(\"class\", as_index=True).last()\n",
    "    return acc, df_pred, diag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Run cross-platform evaluation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_once(seed, sets, weights, neg_per_pos=5):\n",
    "    acc, df_pred, diag = classify_by_ttest_custom(\n",
    "        adata_new, sets_dict=sets, weights_dict=weights,\n",
    "        K=100, neg_per_pos=neg_per_pos, agg=\"weighted\", trim_pct=0.10,\n",
    "        seed=seed, boot_idx=None\n",
    "    )\n",
    "    return float(acc), df_pred, diag\n",
    "\n",
    "# Sweep across seeds\n",
    "SEEDS = [1,2,3,4,5, 6, 7, 8, 9, 10]\n",
    "acc_llm, acc_mrk = [], []\n",
    "for s in SEEDS:\n",
    "    aL, *_ = run_once(s, ref_llm_top_X, ref_llm_w_X, neg_per_pos=5)\n",
    "    aM, *_ = run_once(s, marker_top_X,  marker_w_X,  neg_per_pos=5)\n",
    "    acc_llm.append(aL); acc_mrk.append(aM)\n",
    "\n",
    "print(\"LLM runs:\", np.round(acc_llm, 3).tolist())\n",
    "print(\"MRK runs:\", np.round(acc_mrk, 3).tolist())\n",
    "\n",
    "def mean_ci95(a):\n",
    "    a = np.asarray(a, float); n=len(a); m=np.mean(a)\n",
    "    sd = np.std(a, ddof=1) if n>1 else 0.0\n",
    "    tcrit = student_t.ppf(0.975, n-1) if n>1 else 0.0\n",
    "    half = tcrit * sd / np.sqrt(n) if n>1 else 0.0\n",
    "    return m, half\n",
    "\n",
    "def paired_stats(a, b):\n",
    "    a, b = np.asarray(a, float), np.asarray(b, float)\n",
    "    t_res = ttest_rel(a, b)\n",
    "    try:\n",
    "        w_res = wilcoxon(a, b, zero_method=\"wilcox\")\n",
    "        w_p = w_res.pvalue\n",
    "    except Exception:\n",
    "        w_p = np.nan\n",
    "    return t_res.statistic, t_res.pvalue, w_p\n",
    "\n",
    "def plot_acc_ci(acc_llm, acc_mrk, title=\"MERFISH → Stereo-seq (no-disjoint)\", outfile=\"fig_llm_vs_markers.png\"):\n",
    "    mA, ciA = mean_ci95(acc_llm); mB, ciB = mean_ci95(acc_mrk)\n",
    "    _, p_t, p_w = paired_stats(acc_llm, acc_mrk)\n",
    "\n",
    "    x = np.array([0,1], float)\n",
    "    fig, ax = plt.subplots(1,1, figsize=(5.5,4), dpi=150)\n",
    "    ax.bar(x, [mA, mB], yerr=[ciA, ciB], width=0.6,\n",
    "           capsize=5, alpha=0.7, edgecolor=\"black\")\n",
    "\n",
    "    rng = np.random.default_rng(123)\n",
    "    j1 = x[0] + rng.normal(0, 0.03, size=len(acc_llm))\n",
    "    j2 = x[1] + rng.normal(0, 0.03, size=len(acc_mrk))\n",
    "    ax.scatter(j1, acc_llm, s=18, zorder=3)\n",
    "    ax.scatter(j2, acc_mrk, s=18, zorder=3)\n",
    "    for xi, yi, xj, yj in zip(j1, acc_llm, j2, acc_mrk):\n",
    "        ax.plot([xi, xj], [yi, yj], color=\"0.7\", lw=0.8, zorder=2)\n",
    "\n",
    "    ax.set_xticks(x); ax.set_xticklabels([\"LLM (frozen)\", \"Markers\"])\n",
    "    ax.set_ylim(0.0, 1.05); ax.set_ylabel(\"Accuracy\")\n",
    "    ax.grid(axis=\"y\", ls=\"--\", alpha=0.3)\n",
    "    ax.set_title(title + f\"\\npaired t p={p_t:.2e} | Wilcoxon p={p_w:.2e}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outfile, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"Saved:\", outfile)\n",
    "\n",
    "plot_acc_ci(acc_llm, acc_mrk)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
